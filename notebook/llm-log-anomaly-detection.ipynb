{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090d7c39-57b0-4265-a04d-f676061ca009",
   "metadata": {},
   "source": [
    "# Log Anomaly Detection using fine tunned LLM\n",
    "Classify anomaly log sequences using fine tunned LLM for BlueGene/L supercomputer system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d54153-f1e0-4642-bab2-1b55e0fcdbe6",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f670edd-ad60-4c09-a520-abc45ccffa37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/snanda14/.local/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /home/snanda14/.local/lib/python3.12/site-packages (4.45.1)\n",
      "Requirement already satisfied: peft in /home/snanda14/.local/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: datasets in /home/snanda14/.local/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: pandas in /home/snanda14/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/snanda14/.local/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/snanda14/.local/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pyreft in /home/snanda14/.local/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: seaborn in /home/snanda14/.local/lib/python3.12/site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib in /home/snanda14/.local/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: drain3 in /home/snanda14/.local/lib/python3.12/site-packages (0.9.11)\n",
      "Requirement already satisfied: filelock in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/snanda14/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/snanda14/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/snanda14/.local/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/snanda14/.local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/snanda14/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/snanda14/.local/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/snanda14/.local/lib/python3.12/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/snanda14/.local/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/snanda14/.local/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/snanda14/.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/snanda14/.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/snanda14/.local/lib/python3.12/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/snanda14/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/snanda14/.local/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/snanda14/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/snanda14/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pyvene>=0.1.7 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (0.1.7)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (3.20.3)\n",
      "Requirement already satisfied: ipywidgets>=8.1.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from pyreft) (8.1.5)\n",
      "Requirement already satisfied: plotnine>=0.12.4 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (0.14.5)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (0.2.0)\n",
      "Requirement already satisfied: evaluate>=0.4.1 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (0.4.3)\n",
      "Requirement already satisfied: wandb in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (0.19.10)\n",
      "Requirement already satisfied: jupyter in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from pyreft) (1.1.1)\n",
      "Requirement already satisfied: ydata-profiling>=4.7.0 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (4.16.1)\n",
      "Requirement already satisfied: gcsfs>=2024.2.0 in /home/snanda14/.local/lib/python3.12/site-packages (from pyreft) (2024.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from matplotlib) (3.2.2)\n",
      "Requirement already satisfied: jsonpickle==1.5.1 in /home/snanda14/.local/lib/python3.12/site-packages (from drain3) (1.5.1)\n",
      "Requirement already satisfied: cachetools==4.2.1 in /home/snanda14/.local/lib/python3.12/site-packages (from drain3) (4.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/snanda14/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: decorator>4.1.2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from gcsfs>=2024.2.0->pyreft) (5.2.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /home/snanda14/.local/lib/python3.12/site-packages (from gcsfs>=2024.2.0->pyreft) (2.39.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /home/snanda14/.local/lib/python3.12/site-packages (from gcsfs>=2024.2.0->pyreft) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-storage in /home/snanda14/.local/lib/python3.12/site-packages (from gcsfs>=2024.2.0->pyreft) (3.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipywidgets>=8.1.1->pyreft) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipywidgets>=8.1.1->pyreft) (8.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipywidgets>=8.1.1->pyreft) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipywidgets>=8.1.1->pyreft) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipywidgets>=8.1.1->pyreft) (3.0.13)\n",
      "Requirement already satisfied: mizani~=0.13.0 in /home/snanda14/.local/lib/python3.12/site-packages (from plotnine>=0.12.4->pyreft) (0.13.3)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /home/snanda14/.local/lib/python3.12/site-packages (from plotnine>=0.12.4->pyreft) (0.14.4)\n",
      "Requirement already satisfied: six>=1.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: pydantic>=2 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (2.11.3)\n",
      "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /home/snanda14/.local/lib/python3.12/site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.7.0->pyreft) (0.8.1)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (0.12.4)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (1.12)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (4.4.2)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (1.9.2)\n",
      "Requirement already satisfied: numba<=0.61,>=0.56.0 in /home/snanda14/.local/lib/python3.12/site-packages (from ydata-profiling>=4.7.0->pyreft) (0.61.0)\n",
      "Requirement already satisfied: PyWavelets in /home/snanda14/.local/lib/python3.12/site-packages (from imagehash==4.3.1->ydata-profiling>=4.7.0->pyreft) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: notebook in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter->pyreft) (7.3.3)\n",
      "Requirement already satisfied: jupyter-console in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter->pyreft) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter->pyreft) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter->pyreft) (6.29.5)\n",
      "Requirement already satisfied: jupyterlab in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter->pyreft) (4.3.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/snanda14/.local/lib/python3.12/site-packages (from wandb->pyreft) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/snanda14/.local/lib/python3.12/site-packages (from wandb->pyreft) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/snanda14/.local/lib/python3.12/site-packages (from wandb->pyreft) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from wandb->pyreft) (4.3.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/snanda14/.local/lib/python3.12/site-packages (from wandb->pyreft) (2.27.0)\n",
      "Requirement already satisfied: setproctitle in /home/snanda14/.local/lib/python3.12/site-packages (from wandb->pyreft) (1.3.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/snanda14/.local/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->pyreft) (4.0.12)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/snanda14/.local/lib/python3.12/site-packages (from google-auth>=1.2->gcsfs>=2024.2.0->pyreft) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/snanda14/.local/lib/python3.12/site-packages (from google-auth>=1.2->gcsfs>=2024.2.0->pyreft) (4.9.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.6.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/snanda14/.local/lib/python3.12/site-packages (from numba<=0.61,>=0.56.0->ydata-profiling>=4.7.0->pyreft) (0.44.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/snanda14/.local/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling>=4.7.0->pyreft) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/snanda14/.local/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling>=4.7.0->pyreft) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/snanda14/.local/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling>=4.7.0->pyreft) (0.4.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/snanda14/.local/lib/python3.12/site-packages (from statsmodels>=0.14.0->plotnine>=0.12.4->pyreft) (1.0.1)\n",
      "Requirement already satisfied: puremagic in /home/snanda14/.local/lib/python3.12/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.7.0->pyreft) (1.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/snanda14/.local/lib/python3.12/site-packages (from google-auth-oauthlib->gcsfs>=2024.2.0->pyreft) (2.0.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /home/snanda14/.local/lib/python3.12/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft) (2.25.0rc0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /home/snanda14/.local/lib/python3.12/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /home/snanda14/.local/lib/python3.12/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/snanda14/.local/lib/python3.12/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft) (1.7.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (1.8.13)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (26.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from ipykernel->jupyter->pyreft) (6.4.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab->jupyter->pyreft) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->pyreft) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbconvert->jupyter->pyreft) (1.5.0)\n",
      "Requirement already satisfied: webencodings in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->pyreft) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->pyreft) (1.4.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/snanda14/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->pyreft) (5.0.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/snanda14/.local/lib/python3.12/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.2.0->pyreft) (1.70.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home/snanda14/.local/lib/python3.12/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.2.0->pyreft) (1.26.1)\n",
      "Requirement already satisfied: anyio in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->pyreft) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->pyreft) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->pyreft) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.8.4)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert->jupyter->pyreft) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/snanda14/.local/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.2.0->pyreft) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/snanda14/.local/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.2.0->pyreft) (3.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter->pyreft) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->pyreft) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (21.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->pyreft) (0.23.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->pyreft) (2.9.0.20241206)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers peft datasets pandas numpy scikit-learn pyreft seaborn matplotlib drain3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b43ea6f-7375-4e83-b7c8-b3d5b7f6a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a802104b-93aa-4a2c-9003-2eff7296b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0f44b-5247-43c4-a818-fb781641d2bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db18c3-fa39-4c13-a8ab-5160409c707d",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7fbe7-3e1e-461a-bfec-97dc005eaecd",
   "metadata": {},
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370b44e6-8fe3-444e-bfb5-3dc2e84b9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BGL data\n",
    "log_df = pd.read_csv(\"./data/BGL_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43140a1e-6d91-4c29-916a-068fa55fcd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Time</th>\n",
       "      <th>NodeRepeat</th>\n",
       "      <th>Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>E77</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineId Label   Timestamp        Date                 Node  \\\n",
       "0       1     -  1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "\n",
       "                         Time           NodeRepeat Type Component Level  \\\n",
       "0  2005-06-03-15.42.50.675872  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "\n",
       "                                    Content EventId  \\\n",
       "0  instruction cache parity error corrected     E77   \n",
       "\n",
       "                              EventTemplate  \n",
       "0  instruction cache parity error corrected  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1905fcf-e111-41c1-8cac-2e18499dba02",
   "metadata": {},
   "source": [
    "#### 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45276f80-ff89-44b5-8c9c-a509c6d7d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean df\n",
    "log_df.dropna()\n",
    "\n",
    "# replace anomaly and normal labels to '1' & '0' respectively\n",
    "log_df['Label'] = log_df['Label'].apply(lambda x: 0 if x == '-' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832f1c0c-3278-4fbd-a1c9-3cce4697b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine columns to make it nore meaninful \n",
    "log_df['Description'] = '[' + log_df['Level'].astype(str) + '] ' + log_df['EventTemplate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2bd3cb-fee2-4bc6-9837-8f981d1a02e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Time</th>\n",
       "      <th>NodeRepeat</th>\n",
       "      <th>Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>E77</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[INFO] instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineId  Label   Timestamp        Date                 Node  \\\n",
       "0       1      0  1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "\n",
       "                         Time           NodeRepeat Type Component Level  \\\n",
       "0  2005-06-03-15.42.50.675872  R02-M1-N0-C:J12-U11  RAS    KERNEL  INFO   \n",
       "\n",
       "                                    Content EventId  \\\n",
       "0  instruction cache parity error corrected     E77   \n",
       "\n",
       "                              EventTemplate  \\\n",
       "0  instruction cache parity error corrected   \n",
       "\n",
       "                                       Description  \n",
       "0  [INFO] instruction cache parity error corrected  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef7d0bb-b133-4c86-bf61-1653a3905717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    1857\n",
      "1     143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3c8c2-2cad-4d91-b01a-2d9360c96748",
   "metadata": {},
   "source": [
    "#### 3. Sequence windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5792e0-8734-4b43-9b0b-d5e153f851a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each sequence window size\n",
    "window_size = 10\n",
    "# how much window to slide \n",
    "stride = 3\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# combines 10 consecutive rows into a one sequence\n",
    "for i in range(0, len(log_df) - window_size + 1, stride):\n",
    "    sequence = ' '.join(log_df['Description'][i:i + window_size].astype(str))\n",
    "    seq_label = log_df['Label'][i:i + window_size].max()\n",
    "    sequences.append(sequence)\n",
    "    labels.append(seq_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87d8b8-fb3a-4268-8cd3-32d901260f34",
   "metadata": {},
   "source": [
    "#### 4. Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e44bcf-4e92-47b5-bc89-3d9391e9f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 664\n",
      "Train sequences: 531 | Anomalous: 98 (18.46%)\n",
      "Test sequences: 133 | Anomalous: 32 (24.06%)\n"
     ]
    }
   ],
   "source": [
    "# split sequences and labels into - 80% training & 20% testing\n",
    "train_seqs, test_seqs, train_labels, test_labels = train_test_split(\n",
    "    sequences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total sequences: {len(train_seqs) + len(test_seqs)}\")\n",
    "print(f\"Train sequences: {len(train_seqs)} | Anomalous: {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.2f}%)\")\n",
    "print(f\"Test sequences: {len(test_seqs)} | Anomalous: {sum(test_labels)} ({sum(test_labels)/len(test_labels)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc11204-5c08-4347-85eb-8f1a2c31619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract anomaly sequences\n",
    "anomaly_seqs = [seq for seq, label in zip(train_seqs, train_labels) if label == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c517fb-f255-4dde-93b0-ea8155fc64c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256c819-43c0-4873-a25a-4ad7735589bb",
   "metadata": {},
   "source": [
    "## Tokenization & Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a85521-10c9-4866-821e-ac778116ec9b",
   "metadata": {},
   "source": [
    "#### 1. Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efe33ec1-4b5d-4b22-9644-98345118fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "\n",
    "# utility function to convert logs into model ready inputs \n",
    "def tokenize_sequences(sequences, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        sequences,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e8138-f833-479d-b731-b22d875322f6",
   "metadata": {},
   "source": [
    "#### 2. Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b57a876-e694-40ab-8b67-1a238abafcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to PyTorch dataset\n",
    "class LogDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8475f8-ada1-4f80-bef1-4016a19849db",
   "metadata": {},
   "source": [
    "#### 3. Tokenize sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fc4768-8c67-43f7-b1a0-92bbcf9cbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "train_encodings = tokenize_sequences(train_seqs, tokenizer)\n",
    "test_encodings = tokenize_sequences(test_seqs, tokenizer)\n",
    "\n",
    "# create datasets\n",
    "train_dataset = LogDataset(train_encodings, train_labels)\n",
    "test_dataset = LogDataset(test_encodings, test_labels)\n",
    "\n",
    "# create loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8a2dd-043b-445c-becc-8959171d0115",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0cc8f-4e0c-4bcc-9e41-a8d9be759550",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a51e90-700b-4eec-a1f7-4368a0b44638",
   "metadata": {},
   "source": [
    "#### 1. Prepare model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab4520b-5571-4033-9f33-618f14f4fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_MODEL_LOCATION=\"./model/classifier/anomaly_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6117cc3-c3b0-465e-baa2-4a5683159e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train_model(model, train_loader, test_loader, device, epochs=10, patience=5):\n",
    "    model.to(device)\n",
    "    # intialise AdamW optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    # small learning rate so it wonâ€™t overshoot\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    # handle classs imbalance with higher weight\n",
    "    # weighted loss to penalize for misclassifying the minority class\n",
    "    class_weights = torch.tensor([1.0, 6.0]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "    # track early stopping\n",
    "    best_f1 = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(f\"\\nTraining... | No. of Epochs: {epochs}...\\n\")\n",
    "    \n",
    "    # Train model\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "\n",
    "            # reset gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get the input data and labels from the batch, move them to the device (GPU/CPU)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "                        \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "                        \n",
    "            # update model weight\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for logging purposes\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # adjust learning rate\n",
    "        scheduler.step()\n",
    "        # average loss for the epoch\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "        \n",
    "        # Evaluate to check for early stopping\n",
    "        f1, _, _, _ = evaluate_model(model, test_loader, device)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            patience_counter = 0\n",
    "            model.save_pretrained(CLASSIFICATION_MODEL_LOCATION)\n",
    "            tokenizer.save_pretrained(CLASSIFICATION_MODEL_LOCATION)\n",
    "            print(\"\\n########################################\\n\")\n",
    "        else:\n",
    "            # If no improvement in F1 score, stop training early\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"\\nEarly stopping...\\n\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5468c-6f81-4da9-8ff1-a5de0c4e5673",
   "metadata": {},
   "source": [
    "#### 2. Prepare model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "247dae19-3b24-42ff-89d6-dff343ee8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance with threshold\n",
    "def evaluate_model(model, test_loader, device, threshold=0.1039):\n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    # disable gradient\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits[:, 1]  # Score for class 1\n",
    "\n",
    "            # predict anomaly\n",
    "            preds = (logits > threshold).cpu().numpy().astype(int)\n",
    "\n",
    "            # store predeiction\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # calcuate metrics\n",
    "    f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "    precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    \n",
    "    print(f\"\\nF1: {f1:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(true_labels, predictions)}\\n\")\n",
    "    return f1, precision, recall, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018b8b4-0409-4c56-8bd8-0c4e0bad972f",
   "metadata": {},
   "source": [
    "#### 3. Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a46f45-72be-4986-8e41-fda1c0351089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    llm_model,\n",
    "    num_labels=2,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258aa453-603f-4851-be1b-6678e6cff0ea",
   "metadata": {},
   "source": [
    "#### 4. Setup Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c4308a2-4170-4926-b073-21291d4c9221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,131,712 || all params: 1,040,648,192 || trainable%: 0.5892\n"
     ]
    }
   ],
   "source": [
    "# define lora\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", # for binary classification\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a93d62-5291-4e07-9263-e441fc498c50",
   "metadata": {},
   "source": [
    "#### 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e75e7396-55b9-4c36-885a-4e9b4cd8305a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training... | No. of Epochs: 10...\n",
      "\n",
      "Epoch 1, Loss: 0.37547447665858624\n",
      "\n",
      "F1: 0.7294\n",
      "Precision: 0.5849\n",
      "Recall: 0.9688\n",
      "\n",
      "Confusion Matrix:\n",
      " [[79 22]\n",
      " [ 1 31]]\n",
      "\n",
      "\n",
      "########################################\n",
      "\n",
      "Epoch 2, Loss: 0.1091395245088306\n",
      "\n",
      "F1: 0.9062\n",
      "Precision: 0.9062\n",
      "Recall: 0.9062\n",
      "\n",
      "Confusion Matrix:\n",
      " [[98  3]\n",
      " [ 3 29]]\n",
      "\n",
      "\n",
      "########################################\n",
      "\n",
      "Epoch 3, Loss: 0.04279728729535005\n",
      "\n",
      "F1: 0.8857\n",
      "Precision: 0.8158\n",
      "Recall: 0.9688\n",
      "\n",
      "Confusion Matrix:\n",
      " [[94  7]\n",
      " [ 1 31]]\n",
      "\n",
      "Epoch 4, Loss: 0.01676592217081091\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "\n",
      "########################################\n",
      "\n",
      "Epoch 5, Loss: 0.001822015946379282\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "Epoch 6, Loss: 0.0007382053914191045\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "Epoch 7, Loss: 0.0006776269121691081\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "Epoch 8, Loss: 0.0006584040680984378\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "Epoch 9, Loss: 0.0006471249606902212\n",
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n",
      "\n",
      "Early stopping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_model(model, train_loader, test_loader, device, epochs=10, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a3fd6-76fd-4f95-94f2-a5105f64b72a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90018e5b-e190-4dbf-9005-d0ed940adca6",
   "metadata": {},
   "source": [
    "## Modal Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef26be4-5340-4f40-9467-9c030f56cdb2",
   "metadata": {},
   "source": [
    "#### 1. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9a503d-805f-431f-acf1-51aa680f9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.9697\n",
      "Precision: 0.9412\n",
      "Recall: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[99  2]\n",
      " [ 0 32]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLASSIFICATION_MODEL_LOCATION)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(llm_model, num_labels=2, pad_token_id=tokenizer.pad_token_id)\n",
    "model = PeftModel.from_pretrained(model, CLASSIFICATION_MODEL_LOCATION)\n",
    "model.to(device)\n",
    "\n",
    "# evaluate\n",
    "_, _, _, predictions = evaluate_model(model, test_loader, device, threshold=0.1039)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78547db0-5f35-4f98-bdfe-568fe4a5a2cd",
   "metadata": {},
   "source": [
    "#### 2. Evaluate with threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc438926-83b5-48b7-b30f-28c3d51060f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best threshold based on F1 score\n",
    "def evaluate_model_with_threshold(model, test_loader, device):\n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    logits = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # disable gradient\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits.extend(outputs.logits[:, 1].cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    # calculate precision & recall\n",
    "    precisions, recalls, thresholds = precision_recall_curve(true_labels, logits)\n",
    "    # F1 score\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    # index of best F1 score\n",
    "    best_idx = f1_scores.argmax()\n",
    "\n",
    "    # best threshold\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    \n",
    "    print(f\"\\nBest F1: {f1_scores[best_idx]:.4f}\\nPrecision: {precisions[best_idx]:.4f}\\n\"\n",
    "          f\"Recall: {recalls[best_idx]:.4f}\\nThreshold: {best_threshold:.4f}\\n\")\n",
    "\n",
    "    return true_labels, logits, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a93a9e3-def2-4074-860e-e9a42bd15cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1: 0.9841\n",
      "Precision: 1.0000\n",
      "Recall: 0.9688\n",
      "Threshold: 1.4070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find best threshold\n",
    "true_labels, logits, best_threshold = evaluate_model_with_threshold(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50bb9c-086a-4595-8653-9b43cd9f6466",
   "metadata": {},
   "source": [
    "#### 3. Plot Precission Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9634c445-975c-4ca1-8c08-f50b6056bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate & plot\n",
    "precisions, recalls, thresholds = precision_recall_curve(true_labels, logits)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recalls, precisions, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31be20c-8bcc-49df-96b0-81ce919d45fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ce6d3-51e7-437a-8136-65a4fbbf7ccb",
   "metadata": {},
   "source": [
    "## Fine-tuning LLM for reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72836e33-4805-4e54-af74-f42ad695a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f1cd5-427c-4e8a-b7fe-04858084a946",
   "metadata": {},
   "source": [
    "#### 1. Load dataset & create train test split\n",
    "Created reasoning for each anomaly sequence and a synthetic dataset can be created by running the script `synthetic_log_explaination.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4830235c-a1ee-4983-a5c3-a9844595b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a dataset with 98 sequences & 98 of their reasons, & stored in './data/anomaly_explantion.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!python ./synthetic_log_explaination.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1f1d72c-e535-45e8-95da-cbd6a1f8ed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[FATAL] Lustre mount FAILED : bglio&lt;*&gt; : point...</td>\n",
       "      <td>Storage mount failures, debugger crashes, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  [FATAL] Lustre mount FAILED : bglio<*> : point...   \n",
       "\n",
       "                                              reason  \n",
       "0  Storage mount failures, debugger crashes, and ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "reasoning_df = pd.read_csv('./data/anomaly_explantion.csv')\n",
    "reasoning_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f74cd60-1666-49b8-935f-dd2e45d7e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_reasoning, test_reasoning = train_test_split(\n",
    "    reasoning_df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29eeede-0919-40ca-8efc-116aa6022875",
   "metadata": {},
   "source": [
    "#### 2. Create custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72b789fd-09a9-4200-8ca3-bef86af4456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReasoningDataset(Dataset):\n",
    "    def __init__(self, sequences, reasons, tokenizer, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.reasons = reasons\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        reason = self.reasons[idx]\n",
    "        text = f\"Sequence: {sequence} Reason: {reason}\"\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': encodings['input_ids'].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f5740-3f40-46d6-9d14-7414840d2d16",
   "metadata": {},
   "source": [
    "#### 3. Load Tokenizer and create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ac87a4-d636-4246-b04e-9cbaa6930d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcdef776-9233-464f-aa77-f657e49e485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer_reasoning = AutoTokenizer.from_pretrained(reasoning_model)\n",
    "    \n",
    "if tokenizer_reasoning.pad_token is None:\n",
    "    tokenizer_reasoning.pad_token = tokenizer.eos_token\n",
    "    tokenizer_reasoning.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da4d448f-2f17-4c9e-9b4b-8bdc53720960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reasoning dataset\n",
    "train_reasoning_dataset = ReasoningDataset(\n",
    "    train_reasoning['sequence'].tolist(),\n",
    "    train_reasoning['reason'].tolist(),\n",
    "    tokenizer_reasoning\n",
    ")\n",
    "test_reasoning_dataset = ReasoningDataset(\n",
    "    test_reasoning['sequence'].tolist(),\n",
    "    test_reasoning['reason'].tolist(),\n",
    "    tokenizer_reasoning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b406cf1-e064-4885-8cb1-07b0bca8c6e8",
   "metadata": {},
   "source": [
    "#### 4. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c33851bc-9cfc-4ce7-83d1-c751f7442e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "reasoning_model = AutoModelForCausalLM.from_pretrained(reasoning_model)\n",
    "reasoning_model.tokenizer = tokenizer_reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ee3a0-351b-4f7d-90cd-0284bac76b1d",
   "metadata": {},
   "source": [
    "#### 5. Setup lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa25bda4-ccaa-497b-bd5e-fe0bdefe16e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,127,616 || all params: 1,106,176,000 || trainable%: 0.5539\n"
     ]
    }
   ],
   "source": [
    "# configure lora\n",
    "reasoning_lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"]\n",
    ")\n",
    "\n",
    "reasoning_model = get_peft_model(reasoning_model, reasoning_lora_config)\n",
    "reasoning_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65dfb34-05b7-4ba8-a463-cef64cc88725",
   "metadata": {},
   "source": [
    "#### 6. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2059ba4a-371e-406d-a81a-86923b222639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 07:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.327400</td>\n",
       "      <td>4.973135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.711100</td>\n",
       "      <td>2.060183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>0.767085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.613600</td>\n",
       "      <td>0.677140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.599949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.536610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.495266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.339300</td>\n",
       "      <td>0.467832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.453830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.449233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=1.4501865983009339, metrics={'train_runtime': 462.3836, 'train_samples_per_second': 1.687, 'train_steps_per_second': 0.433, 'total_flos': 2493539942400000.0, 'train_loss': 1.4501865983009339, 'epoch': 10.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define training args\n",
    "reasoning_training_args = TrainingArguments(\n",
    "    output_dir=\"./model/reasoning/checkpoints\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# train model\n",
    "reasoning_trainer = Trainer(\n",
    "    model=reasoning_model,\n",
    "    args=reasoning_training_args,\n",
    "    train_dataset=train_reasoning_dataset,\n",
    "    eval_dataset=test_reasoning_dataset,\n",
    "    tokenizer=tokenizer_reasoning\n",
    ")\n",
    "reasoning_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4a4b-21fe-4e1b-8a72-55706421d4af",
   "metadata": {},
   "source": [
    "#### 7. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4b27252-c5f7-4df2-8ecf-f3a8cb8687e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/reasoning/anomaly_reasoning/tokenizer_config.json',\n",
       " './model/reasoning/anomaly_reasoning/special_tokens_map.json',\n",
       " './model/reasoning/anomaly_reasoning/tokenizer.model',\n",
       " './model/reasoning/anomaly_reasoning/added_tokens.json',\n",
       " './model/reasoning/anomaly_reasoning/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "reasoning_model.save_pretrained(\"./model/reasoning/anomaly_reasoning\")\n",
    "tokenizer_reasoning.save_pretrained(\"./model/reasoning/anomaly_reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77731e6e-5180-4d80-a135-9469d26b1ea8",
   "metadata": {},
   "source": [
    "#### 8. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d976ee4f-5f2d-4d0a-8139-888a37fb74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the reasoning model\n",
    "def evaluate_reasoning_model(model, tokenizer, dataset, device):\n",
    "    \n",
    "    # model evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(min(5, len(dataset))):\n",
    "        sequence = dataset.sequences[i]\n",
    "        true_reason = dataset.reasons[i]\n",
    "        prompt = f\"Sequence: {sequence} Reason:\"\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "        generated_reason = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "        \n",
    "        print(f\"\\nSample {i + 1}:\")\n",
    "        print(f\"\\nSequence: {sequence[:100]}...\")\n",
    "        print(f\"\\nTrue Reason: {true_reason}\")\n",
    "        print(f\"\\nGenerated Reason: {generated_reason}\\n\")\n",
    "        print(\"##################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1db285be-ec07-4173-8361-706cc6041a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "\n",
      "Sequence: [FATAL] Error loading program image (Permission denied), retransmission errors, multiple received si...\n",
      "\n",
      "True Reason: Permission denied errors when loading programs, combined with network retransmission faults and Lustre failures, point to storage and communication breakdown.\n",
      "\n",
      "Generated Reason: Lustre mount failure, repeated permission denial errors, and multiple received signals indicate severe system instability.\n",
      "\n",
      "##################\n",
      "\n",
      "Sample 2:\n",
      "\n",
      "Sequence: [FATAL] data TLB error interrupt [FATAL] data TLB error interrupt ... (10 times total)...\n",
      "\n",
      "True Reason: Massive repeated TLB errors indicate complete breakdown of memory address translation subsystem, critically affecting system operation.\n",
      "\n",
      "Generated Reason: Massive data TLB errors indicate severe memory corruption and system instability.\n",
      "\n",
      "##################\n",
      "\n",
      "Sample 3:\n",
      "\n",
      "Sequence: [FATAL] kernel termination due to bad message header, debug wait hangs, floating point alignment exc...\n",
      "\n",
      "True Reason: Bad message headers, debug waits, and alignment errors leading to core dumps show CPU communication breakdown and kernel-level crashes.\n",
      "\n",
      "Generated Reason: Bad message headers, core dumps, and floating point alignment errors indicate kernel termination due to hardware or software failures.\n",
      "\n",
      "##################\n",
      "\n",
      "Sample 4:\n",
      "\n",
      "Sequence: [INFO] Node card VPD check: U<*> node in processor card slot J<*> do not match. VPD ecid <*>, found ...\n",
      "\n",
      "True Reason: Hardware VPD mismatches and repeated communication packet failures point to hardware configuration or physical installation problems.\n",
      "\n",
      "Generated Reason: Repeated node card VPD check failures, kernel termination, and torus message retransmissions indicate severe system instability and hardware failure.\n",
      "\n",
      "##################\n",
      "\n",
      "Sample 5:\n",
      "\n",
      "Sequence: [FATAL] multiple data storage interrupts and many instruction address faults, followed by storage in...\n",
      "\n",
      "True Reason: Repeated storage interrupts and invalid instruction address accesses indicate full collapse of node memory and CPU stability.\n",
      "\n",
      "Generated Reason: Massive data storage and instruction address faults indicate severe memory corruption and system instability.\n",
      "\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "evaluate_reasoning_model(\n",
    "    reasoning_model,\n",
    "    tokenizer_reasoning,\n",
    "    test_reasoning_dataset,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88813a-e60d-4a39-b155-e7688023f01c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2eea6-a305-4562-8cee-5ac059f2c19f",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "260510d7-39f6-4817-9692-1ead9144b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "from drain3.template_miner import TemplateMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522cd91-594f-4806-a886-117f3074698a",
   "metadata": {},
   "source": [
    "#### 1. Load test logs and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dee3d23-b698-4f6a-a3e0-356a733ff0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"./data/test.log\"\n",
    "with open(log_file_path, \"r\") as file:\n",
    "    logs = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606ec3e1-9891-4f0e-92ad-f7f1c5aea81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- <*> 2005.06.03 R02-M1-N0-C:J12-U11 <*> R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n"
     ]
    }
   ],
   "source": [
    "# data cleanup\n",
    "# drain3: used to encode dynamic fields in raw logs\n",
    "config = TemplateMinerConfig()\n",
    "template_miner = TemplateMiner(config=config)\n",
    "\n",
    "test_logs = []\n",
    "for line in logs:\n",
    "    result = template_miner.add_log_message(line)\n",
    "    if result is not None:\n",
    "        test_logs.append(result[\"template_mined\"])\n",
    "\n",
    "print(test_logs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01375e-4887-4d28-87c0-5a058d48e763",
   "metadata": {},
   "source": [
    "#### 2. Sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d0de0b5-45eb-40bc-87ac-f5af6cf6bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.675872 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected - <*> 2005.06.03 R02-M1-N0-C:J12-U11 <*> R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected - <*> 2005.06.03 R02-M1-N0-C:J12-U11 <*> R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected - <*> 2005.06.03 R02-M1-N0-C:J12-U11 <*> R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected - 1117842440 2005.06.03 R23-M0-NE-C:J05-U01 2005-06-03-16.47.20.730545 R23-M0-NE-C:J05-U01 RAS KERNEL INFO 63543 double-hummer alignment exceptions - <*> 2005.06.03 <*> <*> <*> RAS KERNEL INFO <*> double-hummer alignment exceptions - <*> 2005.06.03 <*> <*> <*> RAS KERNEL INFO <*> double-hummer alignment exceptions - 1117848119 2005.06.03 R16-M1-N2-C:J17-U01 2005-06-03-18.21.59.871925 R16-M1-N2-C:J17-U01 RAS KERNEL INFO CE sym 2, at 0x0b85eee0, mask 0x05 APPREAD 1117869872 2005.06.04 R04-M1-N4-I:J18-U11 2005-06-04-00.24.32.432192 R04-M1-N4-I:J18-U11 RAS APP FATAL ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569 APPREAD <*> 2005.06.04 <*> <*> <*> RAS APP FATAL ciod: failed to read message prefix on control stream (CioStream socket to <*>\n"
     ]
    }
   ],
   "source": [
    "# sliding window\n",
    "window_size = 10\n",
    "stride = 3\n",
    "\n",
    "# Generate sequences\n",
    "sequences = []\n",
    "for i in range(0, len(test_logs) - window_size + 1, stride):\n",
    "    sequence = ' '.join(test_logs[i:i + window_size])\n",
    "    sequences.append(sequence)\n",
    "\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f2dab-e1bc-4303-b296-a9add8235137",
   "metadata": {},
   "source": [
    "#### 3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e019975-eaaf-4583-a650-f1c91af08f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999659c-02c6-450c-9360-445f535920ea",
   "metadata": {},
   "source": [
    "#### 4. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed27199c-f51a-440e-983b-2cdee34dc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLASSIFICATION_MODEL_LOCATION)\n",
    "\n",
    "def tokenize_sequences(sequences, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        sequences,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d093c08-5a98-4e9e-9176-bf0fba15427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "encodings = tokenize_sequences(sequences, tokenizer)\n",
    "dataset = LogDataset(encodings, [0] * len(sequences))\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ba172-ef11-4773-a5e3-c5ac7c3bdf13",
   "metadata": {},
   "source": [
    "####  5. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "756c674d-c40c-41d1-b3dc-ca9c9855ad4b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048, padding_idx=2)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define classfication model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    classification_model_name,\n",
    "    num_labels=2,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "# load the model\n",
    "classification_model = PeftModel.from_pretrained(base_model, CLASSIFICATION_MODEL_LOCATION)\n",
    "classification_model.to(device)\n",
    "classification_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4db409b-3cfa-42c3-ab3a-73f90a075491",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reasoning model\n",
    "reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "reasoning_model = AutoModelForCausalLM.from_pretrained(reasoning_model_name)\n",
    "reasoning_model = PeftModel.from_pretrained(reasoning_model, \"./model/reasoning/anomaly_reasoning\")\n",
    "reasoning_model.to(device)\n",
    "reasoning_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7c4f2-98e4-42eb-a2ea-28442c68f9f0",
   "metadata": {},
   "source": [
    "#### 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cf6fd6c-238e-46bc-b8d2-f43916d5fe67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# is anomaly?\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = classification_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits[:, 1]\n",
    "        preds = (logits > 0.1039).cpu().numpy().astype(int)\n",
    "        predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a139833f-68f5-4861-95be-ae259a18fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate explanation for the detected anomalies\n",
    "max_new_tokens=20\n",
    "anomalous_sequences = []\n",
    "output = []\n",
    "\n",
    "for i, (seq, pred) in enumerate(zip(sequences, predictions)):\n",
    "    explanation = \"\"\n",
    "    if pred == 1:\n",
    "        prompt = f\"Sequence: {seq} Reason:\"\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = reasoning_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "                )\n",
    "        explanation = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "        anomalous_sequences.append((seq, explanation)) # store anomalies\n",
    "    output.append((seq, explanation, pred)) # normal and anomaly data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7967780d-cf62-40cd-9113-201198d0043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('- <*> 2005.06.03 R02-M1-N0-C:J12-U11 <*> R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected - 1117842440 2005.06.03 R23-M0-NE-C:J05-U01 2005-06-03-16.47.20.730545 R23-M0-NE-C:J05-U01 RAS KERNEL INFO 63543 double-hummer alignment exceptions - <*> 2005.06.03 <*> <*> <*> RAS KERNEL INFO <*> double-hummer alignment exceptions - <*> 2005.06.03 <*> <*> <*> RAS KERNEL INFO <*> double-hummer alignment exceptions - 1117848119 2005.06.03 R16-M1-N2-C:J17-U01 2005-06-03-18.21.59.871925 R16-M1-N2-C:J17-U01 RAS KERNEL INFO CE sym 2, at 0x0b85eee0, mask 0x05 APPREAD 1117869872 2005.06.04 R04-M1-N4-I:J18-U11 2005-06-04-00.24.32.432192 R04-M1-N4-I:J18-U11 RAS APP FATAL ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569 APPREAD <*> 2005.06.04 <*> <*> <*> RAS APP FATAL ciod: failed to read message prefix on control stream (CioStream socket to <*> - <*> <*> <*> <*> <*> RAS KERNEL INFO CE sym <*> at <*> mask <*> - 1117955341 2005.06.05 R25-M0-N7-C:J02-U01 2005-06-05-00.09.01.903373 R25-M0-N7-C:J02-U01 RAS KERNEL INFO generating core.2275 - <*> 2005.06.05 <*> <*> <*> RAS KERNEL INFO generating <*>',\n",
       " 'Repeated double-hummer alignment and CE syms, repeated core.2275')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalous_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a565ca6-27d7-4b04-b4a8-e833635ba22c",
   "metadata": {},
   "source": [
    "#### 7. Store model output as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d634b20-064d-47e1-8b4a-c61fa66bd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output, columns=['Sequence', 'Explanation', 'Prediction'])\n",
    "df.to_csv('./data/output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e0f74-ba97-40c1-9a36-f7e54faf20a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658054f2-fd7c-41d7-bd32-07ee40b68cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
